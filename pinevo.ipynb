{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50ce8d63-6c80-4326-8f7b-028f0dcfc785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pc = Pinecone(api_key=\"949926ec-01d8-40c1\")\n",
    "index = pc.Index(\"test2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "05f738f6-5239-4985-9eb1-10bba491bb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'dimension': 384,\n",
       "              'host': 'test2-ljwx5f4.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'test2',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34bfcefd-96df-4eb6-986f-d741230f34d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH=\"/home/sets/PycharmProjects/llm/mistral_chatbot/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d88e8b39-4b05-4c31-91a8-7d7beb0d2757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs Loaded\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader\n",
    "dir_loader = DirectoryLoader(\n",
    "    DATA_DIR_PATH,\n",
    "    glob='*.txt',\n",
    "    loader_cls=TextLoader\n",
    ")\n",
    "docs = dir_loader.load()\n",
    "print(\"PDFs Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "469683c1-7d5a-475a-9934-e2fb9b677751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "txt_splitter = RecursiveCharacterTextSplitter(separators=['[splixt]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e97b9afb-f613-4b5b-a959-ef97942d25f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sets/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings,OpenAIEmbeddings\n",
    "inp_txt = txt_splitter.split_documents(docs)\n",
    "\n",
    "hfembeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cuda'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba683eb5-1991-41f3-92ab-1fba72a55c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={'device': 'cuda'}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfembeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "323ca6b6-f8c8-4c17-84d2-6715a3dec71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_txt = txt_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb175128-0b31-466c-92e5-086e1bbf7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x740bc73e7940>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PINECONE_API_KEY'] = \"949926ec-01d8-40c1-a59f-5da066cd75e6\"\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch=PineconeVectorStore.from_texts([t.page_content for t in inp_txt],hfembeddings,index_name='test2')\n",
    "print(docsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80b66a40-9e97-430c-bd0e-9e0d46aab519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llms_model():\n",
    "    llm = CTransformers(model=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", config={'max_new_tokens': 128, 'temperature': 0.5,'context_length': 7000})\n",
    "    return llm\n",
    "llm = create_llms_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "54d992da-9ed9-4418-aae6-85c2aad42199",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated triple-quoted string literal (detected at line 10) (3039903043.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[100], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 10)\n"
     ]
    }
   ],
   "source": [
    "custom_prompt=''With the information provided try to answer the question. If you cant answer the question based \n",
    "on the information either say you cant find an answer or unable to find an answer. So try to understand the context \n",
    "and answer only based on the information provided.pPathaanvrovide true information to and deny if the question is false\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Do provide only helpful answers\n",
    "\n",
    "Helpful answer:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40937b9e-ea9d-4d14-a9d6-27c0b4a8b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 17:53:23.410710: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-28 17:53:23.636189: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-28 17:53:24.112217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd0ce28-9b51-4aaa-bfc5-1724a6816abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sets/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "860c9da2-b6fc-4cb0-9fdd-a0bd093c3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match(input):\n",
    "    input_em = model.encode(input).tolist()\n",
    "    \n",
    "    result = index.query(vector=input_em, top_k=2, includeMetadata=True)\n",
    "    return result['matches'][0]['metadata']['text']+\"\\n\"+result['matches'][1]['metadata']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "215af729-b8ad-4459-8e77-c3402c4a9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=find_match(\"what is the news about loksabha candidate dharmendra yadav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d066a08a-2843-4a1d-b91f-fdb5539a2231",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-community) (5.4.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.0 (from langchain-community)\n",
      "  Downloading langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in ./.local/lib/python3.10/site-packages (from langchain-community) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./.local/lib/python3.10/site-packages (from langchain-community) (0.1.63)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.local/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.local/lib/python3.10/site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.local/lib/python3.10/site-packages (from langchain-community) (8.3.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.local/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in ./.local/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (2020.6.20)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in ./.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: SQLAlchemy, mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, aiosignal, dataclasses-json, aiohttp, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.6 frozenlist-1.4.1 langchain-0.2.1 langchain-community-0.2.1 langchain-text-splitters-0.2.0 marshmallow-3.21.2 multidict-6.0.5 mypy-extensions-1.0.0 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a67f9b2d-99c2-477a-aa10-4f9bc1a8a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.ctransformers import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40c321bb-4008-4c36-995d-de7aebcbcb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llms_model():\n",
    "    llm = CTransformers(model=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", config={'max_new_tokens': 128, 'temperature': 0.5})\n",
    "    return llm\n",
    "llm = create_llms_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "087b83fb-3134-4863-a340-e47bdb6a51d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTransformers(client=<ctransformers.llm.LLM object at 0x740a34e33c10>, model='mistral-7b-instruct-v0.1.Q4_K_M.gguf', config={'max_new_tokens': 128, 'temperature': 0.5})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13a1b776-fb23-4b33-b751-a3ba27dc6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "789bacfe-f9f3-4e7e-b6b9-2c5280edda73",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriveqa=RetrievalQA.from_chain_type(llm=llm,chain_type='stuff',retriever=docsearch.as_retriever(search_kwargs={\"k\": 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d560a4f-2513-4ba4-9780-0c61b0dd192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriveqa.run(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "217bf420-c159-4810-9d11-e6adec3137dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "template = \"\"\"\n",
    "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) Answer the question :\n",
    "------\n",
    "<ctx>\n",
    "{context}\n",
    "</ctx>\n",
    "------\n",
    "<hs>\n",
    "{history}\n",
    "</hs>\n",
    "------\n",
    "{question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"question\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8f6234e7-068c-4c83-be7f-1e6f4f510d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": False,\n",
    "        \"prompt\": prompt,\n",
    "        \"memory\": ConversationBufferMemory(\n",
    "            memory_key=\"history\",\n",
    "            input_key=\"question\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "29416406-8596-4731-a9a2-768f17cb90c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) Answer the question :\n",
      "------\n",
      "<ctx>\n",
      "[splixt]On January 24. 2023, the New York-based  Hindenburg Research brought out a report  titled Adani Group: How The Worldâ€™s 3rd Richest Man Is Pulling The Largest Con In Corporate History accusing the Gautam Adani-led company of â€˜stock manipulation and accounting fraudâ€™ spanning over decades. Hindenburg Research is an investor research firm founded by  Nathan Anderson . Subsequently, the issue raised a huge row in the Parliament and the Congress launched  a nationwide protest . In this context, several Facebook users claimed that Congress leader Rahul Gandhi had met Hindenburg founder Nathan Anderson and shared a photo. Some of the posts can be seen in the following slide-show. This slideshow requires JavaScript. On simply reverse searching the image on  Yandex , Alt News was able to get hold of several media reports from back in 2018 when Congress Leader Rahul Gandhi had visited Germany. The Times of India  carried the photo with a report of Rahul Gandhiâ€™s meeting with German ministers in Hamburg.  The Indian Express  and  The Tribune India  also published similar reports .  The image is from August 22, 2018 and the gentleman beside Rahul is identified in all these reports as  Neils Annen , a minister of state and member of parliament. The following is a screenshot of a PTI story carried by The Indian Express. The official Twitter account of the  Indian National Congress  had tweeted the image and mentioned in caption that the person standing with Rahul was Neils Annen, one of the German leaders he met to discuss various issues. Congress President  @RahulGandhi  met  @NielsAnnen , Minister of State & Member of the Bundestag and discussed Indian & German politics, floods in Kerala, GST & Jobs. #WillkommenRahulGandhi   pic.twitter.com/xLufHI3zY6 â€” Congress (@INCIndia)  August 22, 2018 Hence, the viral image is not of Rahul Gandhi meeting Nathan Anderson. The image is from August 2018 when Gandhi visited Hamburg to meet German policymakers. The gentleman standing with Rahul is Neils Annen, German minister of state and member of parliament. Vansh Shah is an intern with Alt News. Donate Now\n",
      "</ctx>\n",
      "------\n",
      "<hs>\n",
      "Human: did amir khan asked his follower to vote for congress?\n",
      "AI: No, Amir Khan did not ask his followers to vote for Congress. The claim that he made such a request in an Instagram video was proven to be false by a fact-checking website called \"Check News Fact\". According to the website, the video in question was edited and did not actually feature Amir Khan. Furthermore, there is no evidence to suggest that Amir Khan has ever publicly endorsed or supported the Congress party.\n",
      "</hs>\n",
      "------\n",
      "which website referred for it for fact-checking\n",
      "Answer:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Check News Fact'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run({\"query\": \"which website referred for it for fact-checking\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d4e09-0a5b-4a21-906e-40ff46e3f2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fb18b4d-379c-4427-b74f-c2c692268941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "349af7b1-e27a-48e4-bed2-ac9ee37744e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg_template = SystemMessagePromptTemplate.from_template(template=\"\"\"Answer the question as truthfully as possible using the provided {context}, \n",
    "and if the answer is not contained within the text below, say 'I don't know'\"\"\")\n",
    "\n",
    "\n",
    "human_msg_template = HumanMessagePromptTemplate.from_template(template=\"{input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c4a794f3-11a8-4ae0-9f15-15c55d66f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([system_msg_template, MessagesPlaceholder(variable_name=\"history\"), human_msg_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4049360c-9a47-48c0-9ed0-f07000798ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'history', 'input'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"Answer the question as truthfully as possible using the provided {context}, \\nand if the answer is not contained within the text below, say 'I don't know'\")), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "82e2895d-5366-4801-8365-d12e7e082984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "chain = ConversationalRetrievalChain.from_llm(llm=llm, chain_type='stuff',\n",
    "                                              retriever=docsearch.as_retriever(search_kwargs={\"k\": 1})\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "43646892-1837-4194-9810-36a07699a617",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.35.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./.local/lib/python3.10/site-packages (from streamlit) (1.8.2)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./.local/lib/python3.10/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in ./.local/lib/python3.10/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=16.8 in ./.local/lib/python3.10/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in ./.local/lib/python3.10/site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in ./.local/lib/python3.10/site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in ./.local/lib/python3.10/site-packages (from streamlit) (4.25.3)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./.local/lib/python3.10/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./.local/lib/python3.10/site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in ./.local/lib/python3.10/site-packages (from streamlit) (8.3.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in ./.local/lib/python3.10/site-packages (from streamlit) (4.11.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./.local/lib/python3.10/site-packages (from streamlit) (6.4)\n",
      "Collecting watchdog>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas<3,>=1.3.0->streamlit) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (2020.6.20)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.local/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.local/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toolz, toml, smmap, pyarrow, cachetools, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.3.0 cachetools-5.3.3 gitdb-4.0.11 gitpython-3.1.43 pyarrow-16.1.0 pydeck-0.9.1 smmap-5.0.1 streamlit-1.35.0 toml-0.10.2 toolz-0.12.1 watchdog-4.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "917965e3-d689-4adf-ba77-6b2642c227a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 10:51:36.041 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "if 'history' not in st.session_state:\n",
    "    st.session_state['history'] = []\n",
    "\n",
    "if 'generated' not in st.session_state:\n",
    "    st.session_state['generated'] = [\"Hello! Ask me anything about ğŸ¤—\"]\n",
    "\n",
    "if 'past' not in st.session_state:\n",
    "    st.session_state['past'] = [\"Hey! ğŸ‘‹\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cc405689-ffe8-4233-9964-a266d0d3b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain({\"question\": query, \"chat_history\": st.session_state['history']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8b89b048-b5af-43e3-b702-936a25dfa620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'is the viral video of rashmika madhana in lift is true',\n",
       " 'chat_history': [],\n",
       " 'answer': ' No, the viral video of Rashmika Mandanna getting into an elevator is not true. It has been doctored with the help of deepfake technology to make it look like Rashmika Mandanna. The original video was of Zara Patel, a British-Indian girl with 415K followers on Instagram, and was edited by someone else.'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6ce079d-5fce-4f92-90ed-ab6f1c90b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"is the viral video of rashmika madhana in lift is true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3471c4b4-6af1-4bad-8dd2-ace01cf76669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
